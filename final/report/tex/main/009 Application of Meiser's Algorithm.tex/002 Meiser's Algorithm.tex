\section{Meiser's Algorithm}

\nb{For this section, notation is strongly inspired by the notation
used for the detailed explanation of the same problem in \citet*{burgisser:1997}.
The relevant section from this reference is numbered \textbf{3.4} and titled
\emph{Fast Point Location in Arrangement of Hyperplanes}. The algorithm itself
is due to Meiser and can be found in \cite{meiser:1993}.}

Since the beginning of this writing, we were only interested by the number of
questions we ask to an oracle, and we will continue to take the same point of
view here. We wonder how many times we need to ask an oracle whether a point
lies above, on or under a certain hyperplane.

The algorithm we will describe determines the position vector $\pv(x) \in
\signset^{m}$ of input vertex $x \in \R^n$ inside an
arrangement of hyperplanes $\arrangement(\H)$ with $\H$ as a set of hyperplanes
of cardinality $\card{\H} = m = \binom{n}{k}$,
effectively solving the \kSUM problem using \BigO{k n^3 \log^3 n} $n$-variate
linear queries.

For fixed $k$ we draw all hyperplanes having equation involving exactly $k$
coordinates of $\R^n$ with coefficient $1$, we have thus $\card{\H} =
\binom{n}{k}$. We can do this without involving the input vertex at all, this
costs us $0$ queries.

We give each hyperplane an orientation such that when point $x$ is below
hyperplane $H_i$, it is in the lower half-space defined by $H_i$ denoted
$\Him$. When point $x$ is above hyperplane $H_i$ it is in the upper
half-space defined by $H_i$ denoted $\Hip$. We define $\Hiz$ to be the
hyperplane $H_i$ itself. The $i^{th}$ component of the position vector is
$\pv_i(x) = \sigma$ if and only if $x \in \His$.

Our first idea to determine the components of $\pv(x)$ is to iteratively
select a random subset of size \BigO{\poly(n)} constitued of hyperplanes of the
arrangement $\arrangement(\Ht)$ for which the relative position of $x$ has not yet been
determined and compute a position vector for this subset. Once we have located
vertex $x$ inside $\Ht$ we have effectively determined in
which cell of the arrangement $\arrangement(\Ht)$ $x$ lies.

We are left with hyperplanes of the set $\H \setminus \Ht$. They can be
partitioned in two disjoint sets: set $\M$ of hyperplanes that meet the cell of
$\Ht$ containing $x$ and set $\O$ for the others. The relative position of $x$
to each hyperplane belonging to $\O$ can be deduced without the need to query
the oracle, the answer to the queries we would make can be computed by looking
at the structure of the arrangement itself. For the first group of hyperplanes
we just call the procedure again with $\H \gets \M$.

\nb{Note that we always consider that \(x\) is inside a cell that is bounded.
This can be implicitely or explicitely simulated.}

If we stop our explanation here we still have a worst case \BigO{m}
bound on the number of queries made. Hopefully, the next step of our
explanation will show that it is possible to lower this bound.

The problem we have with our current algorithm is that there is no guarantee
on the number of queries we avoid at each step.

We will use a result on \enets, attributed to Ken Clarkson by
\citet{burgisser:1997}, to make our algorithm achieve an upper bound
of \BigO{n^3 \log^2 n \log m} queries.

\begin{theorem}[Clarkson]
Given a set $\H$ of $m$ hyperplanes in $\R^n$ and $\epsilon$ with the
constraint that $0 < \epsilon < 1$, there exists a subset $\NH \subset \H$ of
size $\enetsize$ such that for every simplex $\simplex$ in $\R^n$: if the
number of hyperplanes of $\H$ intersecting $\simplex$ is strictly greater than
$\epsilon \card{\H}$ then at least one of them belongs to $\NH$.
\end{theorem}

By applying a theorem due to \citet*{haussler:1987} on Vapnik-Chervonenkis
dimension and range spaces lemmas, \citet{burgisser:1997} also prove that it is possible to
construct $\NH$ with high probability using a random uniform sampling on $\H$,
meaning the following corollary holds,

\begin{corollary}
If we choose $\enetsize$ hyperplanes uniformly at
random from our $m$ hyperplanes and denote this selection $\H^{*}$ then for
any simplex intersected by more than $\epsilon \card{\H}$ hyperplanes of $\H$
there is a high probability that at least one of them is contained in $\H^{*}$.
\end{corollary}

If we take the contraposition of this corollary we obtain the following one,

\begin{corollary}
If there is no hyperplane $\in \H^{*}$ intersecting a given simplex then, with
high probability, the number of hyperplanes of $\H$ intersecting the simplex
is less or equal to $\epsilon \card{\H}$.
\end{corollary}

We can use this corollary in the algorithm we were just describing earlier. We
now make two changes to the previous algorithm, we explicitely define the
cardinality of $\Ht$ and we include an additional step where we replace cell
$\cell$ with a simplex $\simplex$.

We choose $\card{\Ht} = \enetsize$,
remember $\Ht$ is the set of hyperplanes for which we will query the oracle in
the current step of the algorithm, and instead of directly discarding
hyperplanes not meeting the cell $\cell$ of the arrangement $\arrangement(\Ht)$
containing $x$ we
refine the cell around point $x$ by computing a simplex $\simplex$ inscribed
to $\cell$ and containing $x$, and only after that discard hyperplanes that do
not meet this simplex.

By proceeding this way we have now the guarantee that we will keep at most a
constant fraction ($\epsilon$) of the hyperplanes and thus the total number of
queries made to determine the enclosing cell of
all steps is \BigO{n^2 \log^2 n \log m}. However, we
still need to explicit how we find a simplex $\simplex$ containing $x$ and
inscribed to $\cell$.

We will now explain how to build $\simplex$. The algorithm can be sketched as
follows,

\begin{algorithm}
\item[1.] Find a vertex $\nu$ of the cell containing $x$, $\nu$ is one of
the vertices of our simplex. \textbf{($0$)}
\item[2.] Compute $x'$, the projection of $x$ along $\vec{\nu x}$ on the
opposite face of $\cell$. \textbf{($\enetsize$)}
\item[3.] Induction on $x'$ in $\R^{n-1}$.
\end{algorithm}

We can solve step \textbf{1.} by using linear programming with our
\BigO{n^2 \log^2 n} hyperplanes and the
answers to queries $x \ask{\in} \His, \sigma \in \signset$ as
constraints of the linear program. We just look for any realizable solution.

In step \textbf{2.} we find the projection of $x$ on one of the faces of
$\cell$ by computing the closest hyperplane of $\Ht$ to $x$ in direction
$\vec{\nu x}$. This is done by projecting $x$ on every hyperplane of $\Ht$ and
then computing the distance between $x$ and his projections, keeping the
projection that is the closest in the correct direction as the projection
on $\cell$. Each such projection and distance computation counts as one query
since this computation could be used to forge a query that should have been
forwarded to the oracle.

In step \textbf{3.} the base case is $n = 0$. In $\R^0$ we have only one point
and this point is the last vertex of our simplex.

The recursion depth is $n$, the dimension of $R^n$, and thus the total number
of queries made to compute the $\simplex$ is \BigO{n^3 \log^2 n}.

Remember that once we have the simplex $\simplex$, we do not need to query the input point
$x$ to sort out what meets the $\simplex$ or not. The simplex is composed
entirely of vertices and faces from the hyperplane arrangement $\arrangement(\Ht)$ hence
its structure does not depend on $x$.

Let us recapitulate the algorithm,

\begin{algorithm}
\item[input] $x \in \R^n$, the point to be located
\item[1.] Compute the position of $\BigO{n^2 \log^2 n}$ hyperplanes relatively to
$x$, effectively computing cell $\cell$ containing $x$ \textbf{(\BigO{n^2
\log^2 n})}
\item[2.] Recursively build simplex $\simplex$ containing $x$ and inscribed to $\cell$
\textbf{(\BigO{n^3 \log^2 n})}
\item[3.] For any hyperplane $H_i$ not meeting the simplex, deduce $\pv_i(x)$
\textbf{($0$)}
\item[4.] Discard all hyperplanes that do not meet the inside of the
simplex \textbf{($0$)}
\item[5.] Induction on hyperplanes that are left.
\end{algorithm}

Since the induction depth is $\BigO{\log m}$, the total complexity of this algorithm
is \BigO{n^3 \log^2 n \log m}. For our \kSUM problem, $m = \binom{n}{k}$,
and thus the complexity is \BigO{k n^3 \log^3 n}.

In the next section we will apply the same algorithm to solve the
subset sum problem and see that, with this sufficiently powerful computing
model, it will be possible to solve the subset sum problem in polynomial time.

