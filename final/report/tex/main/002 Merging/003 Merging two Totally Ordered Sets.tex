\section{Merging two Totally Ordered Sets}
\label{tree:merging:k=2}

\subsection*{ITLB}
\label{tree:merging:k=2:ITLB}

Analogously to what was shown in \ref{tree:sorting}, we can compute the
logarithm of the number of possible solutions for this problem, i.e.

\begin{theorem}
The ITLB for the merging problem when \(k = 2\) with \(\card{\S_1} = m, \card{\S_2}
= n\) is \BigOmega{\log \binom{m+n}{m}}.
\end{theorem}

\begin{proof}
We have to choose the $m$ positions among $m+n$ in $\S'$ for the elements of
$\S_1$ and then fill the remaining $(m+n) - m = n$ positions with the elements
of $\S_2$. The number of leaves of the decision tree is $\binom{m+n}{m}$.
Hence, the worst-case minimal height of the tree is $\log \binom{m+n}{m}$.
\end{proof}

\nb{Giving $\log \binom{m+n}{m}$ in the form of the Stirling's approximation
when \(n \ge m\) gives us $(m+n) \log(m+n) - m \log m - n \log n - \BigO{\log
n}$ which clearly expresses the information contained in the sorted sequence
$\S'$ of $m+n$ elements minus the information we already have.}


\subsection*{The Hwang-Lin Algorithm}
\label{tree:merging:k=2:alg}

We will analyse the \concept{ITLB} of the Merging problem. Then we will
describe an algorithm whose complexity meets the \concept{ITLB}. We begin by
computing the general case expression of the \concept{ITLB}.

\begin{lemma}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \log\frac{(m+n)!}{m!n!}\\
&= \log(m+n)! - \log m! - \log n!\\
&= \BigTheta{(m+n) \log(m+n) - m \log m - n \log n}\\
&= \BigTheta{(m+n) \log(m+n) - m \log m - n \log n + (n \log m - n \log m)}\\
&= \BigTheta{(m+n) \log(m+n) - (m+n) \log m - n (\log n - \log m)}\\
&= \BigTheta{(m+n) \log\frac{m+n}{m} - n (\log n - \log m)}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{m} - n (\log n - \log m)}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{\sfrac{m}{m} \cdot n}}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
\end{align*}
\end{proof}

In order to feed our intuition on this expression we will analyze its behaviour
on several special cases. Without loss of generality, we consider the cases
where \(m \leq n\).

The first case we will analyze is the case where $m = n$. This case is similar
to what happens during the merge phase of the \mergesort algorithm.

\begin{lemma}
\begin{align*}
m = n &\implies \log\binom{m+n}{m} = \BigTheta{m + n} = \BigTheta{n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{m \log\frac{2m}{m} + n \log\frac{2n}{n}}\\
&= \BigTheta{m \log 2 + n \log 2}\\
&= \BigTheta{m + n}\\
&= \BigTheta{n}\\
\end{align*}
\end{proof}

An algorithm using at most \(n+m-1\) queries is Tape Merge. Tape Merge is the
merge procedure that \mergesort uses (see step \step{5} of the \mergesort
algorithm in \ref{tree:sorting:alg}), \ie given two linearly ordered sets sort
their union by iteratively removing the smallest element it contains. The union
of the two linearly ordered sets contains \(n+m\) elements. Hence, this
algorithm runs in \(n+m\) iterations. Because the algorithm only needs to
choose between the smallest element of the first linearly ordered set and the
smallest element of the second linearly ordered set at each iteration, each
iteration uses at most one query. At the last iteration, there is only one
element left. Hence, no query is used during the last iteration and the maximum
number of queries this algorithm uses is \(n+m-1\).

Additionally we show what happens when \(m = c n\) for some \(0 < c \le 1\).

\begin{lemma}
\begin{align*}
m = c n \text{ such that } 0 < c \le 1 &\implies \log\binom{m+n}{m} = \BigTheta{n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{cn \log\frac{(1+c)n}{cn} + n \log\frac{(1+c)n}{n}}\\
&= \BigTheta{(1+c)n \log (1+c)n - cn \log cn - n \log n}\\
&= \BigTheta{(1+c)n \log (1+c)n - (1+c)n \log n - cn \log c}\\
&= \BigTheta{(1+c)n \log \frac{(1+c)n}{n} - cn \log c}\\
&= \BigTheta{(1+c)n \log (1+c) - cn \log c}\\
&= \BigTheta{(1+c)n \log (1+c) + cn \log \frac{1}{c}}\\
&= \BigTheta{n}\\
\end{align*}
\end{proof}

In conclusion, the only way the \concept{ITLB} could be \SmallO{n} is if \(m =
\SmallO{n}\). This result will be useful for the next section.

Now we want to see what the bound becomes when $n$ start to grow relatively to
$m$. In the following proof we will assume that $m$ is negligible before $n$.

\begin{lemma}
\begin{align*}
m = \SmallO{n} &\implies \log\binom{m+n}{m} = \BigTheta{m \log\frac{n}{m}}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{m \log\frac{n}{m} + n \log\frac{n}{n}}\\
&= \BigTheta{m \log\frac{n}{m}}\\
\end{align*}
\end{proof}


This could be intuitively understood as doing $m$ binary searches on sets of
size $\frac{n}{m}$.


Now observe what happens when $m = 1$.

\begin{lemma}
\begin{align*}
m = 1 &\implies \log\binom{m+n}{m} = \BigTheta{\log n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{n}{m}}\\
&= \BigTheta{\log n}\\
\end{align*}
\end{proof}

An algorithm performing \BigO{\log n} is Binary Search.


In conclusion, we need an algorithm performing \BigO{m \log\frac{n}{m}}.
Ideally this algorithm should compete with Sequential Merge for the case where
$m = n$ and with Binary Search for the case where $m = 1$.


From now on we have explored special cases, it would be nice if we could
combine the different solutions to build an algorithm of complexity \BigO{\log
\binom{m+n}{m}} that works for any input.

The idea is that the algorithm should behave like:

\begin{itemize}
\item Tape Merge in case $\frac{n}{m} = 1$;
\item $m$ binary searches on sets of size $\frac{n}{m}$ in case $m = \SmallO{n}$;
\item Binary Search in case \(m = \SmallO{n}\) and \(m = 1\).
\end{itemize}

\citet*{DBLP:journals/siamcomp/HwangL72} give such an algorithm. Their
algorithm merges two linearly ordered sets \(\A = \enum{\A_1,\dots,\A_m}\) and
\(\B = \enum{\B_1,\dots,\B_n}\) with the constraint \(m \le n\). Below is a
description of the algorithm:

\begin{algorithm}
\item[1.] If \(m = 0\) the algorithm stops.
\item[2.] Let \(\alpha = \floor{\log \frac{n}{m}}\) and \(x = n - 2^{\alpha} + 1\).
\item[3.] Compare \(\A_m\) with \(\B_x\).
\item[4.] If \(\A_m \le \B_x\), remove all elements \(\B_x,\dots,\B_n\) from
\(\B\).
\item[5.] Otherwise, find the insertion position of \(\A_m\) in
\(\B_{x+1},\dots,\B_{n}\) using binary search. Remove \(\A_m\) from \(\A\) and
remove from \(\B\) the set of all elements that lie after the insertion
position of \(\A_m\) in \(\B\).
\item[6.] If now \(m > n\) swap the roles of \(\A\) and \(\B\).
\item[7.] Merge \(\A\) and \(\B\).
\end{algorithm}

In summary, the algorithm searches the position of the last element of \(\A\)
in the \(2^{\alpha}\) largest elements of \(\B\). If \(\A_m\) is smaller or
equal to all these elements, which can be checked in a single comparison, then
the algorithm discards these elements from \(\B\). Otherwise the algorithm uses
binary search on \(2^{\alpha}-1\) elements to find the insertion position of
\(\A_m\) in \(\B\). In both cases, the last step of the algorithm is to recurse
on the updated sets \(\A\) and \(\B\). The algorithm ensures that \(m \le n\)
before each recursive call.

\citet*{DBLP:journals/siamcomp/HwangL72} prove this algorithm has a complexity
of \(\ceil{\text{ITLB}} + m - 1 = \BigO{ITLB}\). The trick that allows to
get so close to the \concept{ITLB} with this algorithm resides in the choice of
\(\alpha\). Indeed the binary search step uses at most \(\alpha\) comparisons
when \(\alpha\) is a power of \(2\) and when the number of elements to search
from is \(2^{\alpha}-1\).

\nb{We can check that this algorithm matches the \concept{ITLB} found for our
special cases.}
