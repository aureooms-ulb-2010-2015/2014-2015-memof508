\section{Merging two Totally Ordered Sets}
\label{tree:merging:k=2}

\subsection*{ITLB}
\label{tree:merging:k=2:ITLB}

Analogously to what was shown in \ref{tree:sorting}, we can compute the
logarithm of the number of possible solution for this problem, i.e.

\begin{theorem}
The ITLB for the merging problem when \(k = 2\) with \(\card{\S_1} = m, \card{\S_2}
= n\) is \BigOmega{\log \binom{m+n}{m}}.
\end{theorem}

\begin{proof}
We have to choose the $m$ positions among $m+n$ in $\S'$ for the elements of
$\S_1$ and then fill the remaining $(m+n) - m = n$ positions with the elements
of $\S_2$. The number of leaves of the decision tree is $\binom{m+n}{m}$ hence
the worst-case minimal height of the tree is $\log \binom{m+n}{m}$.
\end{proof}

\nb{Giving $\log \binom{m+n}{m}$ in the form of the Stirling's approximation
when \(n \ge m\) gives us $(m+n) \log(m+n) - m \log m - n \log n - \BigO{\log
n}$ which clearly expresses the information contained in the sorted sequence
$\S'$ of $m+n$ elements minus the information we already have.}


\subsection*{The Hwang-Lin Algorithm}
\label{tree:merging:k=2:alg}

We will analyse the \concept{ITLB} of the Merging problem. Then we will
describe an algorithm whose complexity meets the \concept{ITLB}. We begin by
computing the general case expression of the \concept{ITLB}.

\begin{lemma}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \log\frac{(m+n)!}{m!n!}\\
&= \log(m+n)! - \log m! - \log n!\\
&= \BigTheta{(m+n) \log(m+n) - m \log m - n \log n}\\
&= \BigTheta{(m+n) \log(m+n) - m \log m - n \log n + (n \log m - n \log m)}\\
&= \BigTheta{(m+n) \log(m+n) - (m+n) \log m - n (\log n - \log m)}\\
&= \BigTheta{(m+n) \log\frac{m+n}{m} - n (\log n - \log m)}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{m} - n (\log n - \log m)}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{\sfrac{m}{m} \cdot n}}\\
&= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
\end{align*}
\end{proof}

In order to feed our intuition on this expression we will analyze its behaviour
on several special cases. Without loss of generality, we consider the cases
where \(m \leq n\).

The first case we will analyze is the case where $m = n$. This case is similar
to what happens during the merge phase of the merge sort algorithm.

\begin{lemma}
\begin{align*}
m = n &\implies \log\binom{m+n}{m} = \BigTheta{m + n} = \BigTheta{n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{m \log\frac{2m}{m} + n \log\frac{2n}{n}}\\
&= \BigTheta{m \log 2 + n \log 2}\\
&= \BigTheta{m + n}\\
&= \BigTheta{n}\\
\end{align*}
\end{proof}

An algorithm using at most \(n+m-1\) queries is Tapemerge.  Tapemerge is the
merge procedure that Mergesort uses (see step \step{5} of the Mergesort
algorithm in \ref{tree:sorting:alg}), \ie given two linearly ordered sets sort
their union by iteratively removing the smallest element it contains. The union
of the two linearly ordered sets contains \(n+m\) elements, hence this
algorithm runs in \(n+m\) iterations. Because the algorithm only needs to
choose between the smallest element of the first linearly ordered set and the
smallest element of the second linearly ordered set at each iteration, each
iteration uses at most one query. At the last iteration, there is only one
element left, hence no query is used and the maximum number of query this
algorithm uses is \(n+m-1\).

Additionally we show what happens when \(m = c n\) for some \(0 < c \le 1\).

\begin{lemma}
\begin{align*}
m = c n \text{ such that } 0 < c \le 1 &\implies \log\binom{m+n}{m} = \BigTheta{n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{cn \log\frac{(1+c)n}{cn} + n \log\frac{(1+c)n}{n}}\\
&= \BigTheta{(1+c)n \log (1+c)n - cn \log cn - n \log n}\\
&= \BigTheta{(1+c)n \log (1+c)n - (1+c)n \log n - cn \log c}\\
&= \BigTheta{(1+c)n \log \frac{(1+c)n}{n} - cn \log c}\\
&= \BigTheta{(1+c)n \log (1+c) - cn \log c}\\
&= \BigTheta{(1+c)n \log (1+c) + cn \log \frac{1}{c}}\\
&= \BigTheta{n}\\
\end{align*}
\end{proof}

Hence the only way the \concept{ITLB} could be \SmallO{n} is if \(m =
\SmallO{n}\). This result will be useful for the next section.

Now we want to see what the bound becomes when $n$ start to grow relatively to
$m$. In the following proof we will assume that $m$ is negligible before $n$.

\begin{lemma}
\begin{align*}
m = \SmallO{n} &\implies \log\binom{m+n}{m} = \BigTheta{m \log\frac{n}{m}}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{m+n}{m} + n \log\frac{m+n}{n}}\\
&= \BigTheta{m \log\frac{n}{m} + n \log\frac{n}{n}}\\
&= \BigTheta{m \log\frac{n}{m}}\\
\end{align*}
\end{proof}


This could be intuitively understood as doing $m$ binary searches on sets of
size $\frac{n}{m}$.


Now observe what happens when $m = 1$.

\begin{lemma}
\begin{align*}
m = 1 &\implies \log\binom{m+n}{m} = \BigTheta{\log n}\\
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\log\binom{m+n}{m} &= \BigTheta{m \log\frac{n}{m}}\\
&= \BigTheta{\log n}\\
\end{align*}
\end{proof}

An algorithm performing \BigO{\log n} is Binary Search.


In conclusion, we need an algorithm performing \BigO{m \log\frac{n}{m}}.
Ideally this algorithm should compete with Sequential Merge for the case where
$m = n$ and with Binary Search for the case where $m = 1$.


From now on we have explored special cases, it would be nice if we could
combine the different solutions to build an algorithm of complexity \BigO{\log
\binom{m+n}{m}} that works for any input.

The idea is that the algorithm should behave like:

\begin{itemize}
\item Sequential Merge in case $\frac{n}{m} = 1$;
\item $m$ binary searches on sets of size $\frac{n}{m}$ in case $m = \SmallO{n}$;
\item Binary Search in case \(m = \SmallO{n}\) and \(m = 1\).
\end{itemize}

\citet*{DBLP:journals/siamcomp/HwangL72} give such an algorithm.
The algorithm proceeds by reading sequentially every $\frac{n}{m}$ elements of
$\S_2$. Once the algorithm finds the interval of size $\frac{n}{m}$ where the
first element of $\S_1$ is to be found, it applies a binary search algorithm on
this interval. We have the position of the first element.
We now want the position of the second element of $\S_1$. The position of this
second element is necessarily after the position we just found. Thus, if we
proceed in the same manner for all the other elements of $\S_1$ we will only
iterate over the $m$ intervals once and will at most perform $m
\log\frac{n}{m}$ comparisons inside the intervals, hence we get an algorithm
whose complexity is $c \cdot \text{ITLB} + m - 1 = \BigO{ITLB}$.

\nb{We can check that this algorithm matches the \concept{ITLB} found for our
special cases.}
