\section{Stirling's Approximation}
\label{tree:sorting:stirling}

Later on in \ref{tree:supi} we will be interested by counting elements in
finite sets. By counting we mean for an infinite collection of finite sets
$\S_i$ where $i$ ranges over some index set $\I$, \eg $\I = \N$, finding a
counting function $f(i)$ that is valid for all $\S_i$. In general we will only
use the most satisfactory such formula. By most satisfactory we mean a
completely explicit closed formula involving only well-known functions, and
free from summation (and product) symbols. Unfortunately, only in rare cases
will such a formula exist, and the most complicated an expression of $f(i)$
becomes the less we are willing to accept it as a determination
(see \citet*{Stanley:2011:ECV:2124415}, first chapter).

If we take the example of counting \emph{the number of ways a pile of books can
be rearranged}, \ie by permutation of the relative places of books, we can
conclude that for $\S_i$ being the set of all piles containing the same $i$
books we could manage to build by rearranging these $i$ books,

$$ f(i) = i \cdot (i-1) \cdot (i-2) \cdots 3 \cdot 2 \cdot 1 = \prod_{k=1}^i k = i! $$

is an exact formulation. However this formulation contains a product over the range
$[1, i]$ meaning that the computation of the value $f(i)$ would require $i$
multiplications. In fact this is what we wanted to avoid when we said that
there should not be such symbols in the \emph{most satisfactory} formulation.

So, is there a better way? Not always. Considering the general case, only a few
rare counting functions will expose a formulation able to satisfy us. But, for
the example we gave, there is:

\begin{theorem}
\label{tree:sorting:theorem/stirling}
\begin{align*}
n! &\simeq \sqrt{2 \pi n} \left(\frac{n}{e}\right)^n.
\end{align*}
\end{theorem}

Where \(\simeq\) means that the ratio of the two sides tends to \(1\) as \(n\)
tends to infinity.

This satisfactory formula is known as Stirling's approximation (1730). Details
about the proof can be found in \citet*{feller1967direct}.

\ref{tree:sorting:theorem/stirling} gives rise to several corollaries from
which we will retain two.

\begin{corollary}
\begin{align*}
\ln n! &= n \ln n - n + \BigO{\ln n}\\
\end{align*}
\end{corollary}

\begin{corollary}
\label{tree:sorting:corollary/stirling}
\begin{align*}
\log n! &= \BigTheta{n \log n}\\
\end{align*}
\end{corollary}


For example, \ref{tree:sorting:corollary/stirling} will be particularly useful
when proving asymptotic complexity of sorting and merging algorithms, because
of the way these problems are optimally tackled (divide and conquer).

Note that another way of looking at \ref{tree:sorting:corollary/stirling} is
saying that for some constant $c \in \R$ and for some $N \in \R$,

\begin{displaymath}
c \cdot n \log n \leq \log(n!) \leq n \log n, \Forall n \geq N.
\end{displaymath}

