\section{Information-Theoretic Lower Bound}
\label{tree:sorting:ITLB}

The \emph{information-theoretic lower bound} (\ITLB) of a problem
is the minimal depth of any
decision tree solving this problem. Generally speaking, the value of this lower
bound is the logarithm\footnote{Throughout this document, \(\log x\) denotes the binary logarithm of \(x\).}
in base \(2\) of the number of feasible solutions for this problem.

We give the \ITLB for the sorting problem
\begin{theorem}[\ITLB for Sorting]
The \ITLB for the sorting problem is
\(\log(n!)\). For any deterministic algorithm we may think of
there always exists an instance of the problem that forces our
algorithm to ask \(\ceil{\log(n!)}\) questions to the oracle.
\end{theorem}
\begin{proof}
A list \(\S\) of length \(n\) has \(n!\) permutations. A decision tree that sorts
\(\S\) has thus
\(n!\) leaves. Hence, the minimal height of such a tree is at least \(\log(n!)\).
\end{proof}

This lower bound is our goal to attain in terms of number of comparisons
when designing an efficient algorithm solving our problem. The bound only means
that we cannot do better than \(\ceil{\log(n!)}\) comparisons, but it does not
necessarily mean that there exists an algorithm or a decision tree achieving
this bound in terms of complexity.
