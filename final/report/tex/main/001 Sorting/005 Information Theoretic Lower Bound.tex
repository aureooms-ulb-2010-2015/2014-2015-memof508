\section{Information Theoretic Lower Bound}
\label{tree:sorting:ITLB}

We now give the Information Theoretic Lower Bound for the sorting problem. The
Information Theoretic Lower Bound (\define{\ITLB}) is defined as the minimal depth of any
decision tree solving the problem. Generally speaking, the value of this lower
bound is the logarithm\footnote{Throughout this document, \(\log x\) denotes the binary logarithm of \(x\).}
in base \(2\) of the number of feasible solutions.

\begin{theorem}[\ITLB for Sorting]
The Information Theoretic Lower Bound for the sorting problem is
\(\log(n!)\). This means that, for any deterministic algorithm we may think of,
there always exists an instance of the problem that forces our
algorithm to ask \(\ceil{\log(n!)}\) questions to the oracle.
\end{theorem}

\begin{proof}
A sequence \(s\) of length \(n\) has \(n!\) permutations. The decision tree has thus
\(n!\) leaves. Hence, the minimal height of the tree is at least \(\log(n!)\).
\end{proof}

This lower bound is our goal to attain in terms of number of comparisons
when designing an efficient algorithm solving our problem. The bound only means
that we cannot do better than \(\ceil{\log(n!)}\) comparisons but it does not
necessarily mean that there exists an algorithm or a decision tree achieving
this bound in terms of complexity.
